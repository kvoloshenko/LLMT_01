{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w3zhqjRUXnwg",
        "PoIz8Hh30A_N",
        "jJLX5JHD0NH2",
        "eWS8UNbF0aAF",
        "1Dht5DLO0s_V",
        "qCqxIWllq7hy",
        "EpcONB3ottf4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain\n",
        "\n",
        "The sourse idea is here https://youtu.be/aywZrzNaKjs"
      ],
      "metadata": {
        "id": "w3zhqjRUXnwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка библиотек. Сервисные функции"
      ],
      "metadata": {
        "id": "PoIz8Hh30A_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain==0.0.137\n",
        "!pip -q install openai"
      ],
      "metadata": {
        "id": "uxDtIkKKXrrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade tiktoken"
      ],
      "metadata": {
        "id": "c6vrL7JB28XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install openai chromadb"
      ],
      "metadata": {
        "id": "YB4xYxJzxY4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "class MyTools():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  @classmethod\n",
        "  def set_key(cls):\n",
        "      password_input = widgets.Password(\n",
        "          description='Введите OpenAi API key:',\n",
        "          layout=widgets.Layout(width='500px'),\n",
        "          style={'description_width': 'initial', 'white-space': 'pre-wrap', 'overflow': 'auto'})\n",
        "      login_button = widgets.Button(description='Авторизация')\n",
        "      output = widgets.Output()\n",
        "\n",
        "      def on_button_clicked(_):\n",
        "          with output:\n",
        "              api_key = password_input.value\n",
        "              os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "              print(f'{bcolors.OKGREEN}{bcolors.BOLD}Ключ сохранен!{bcolors.ENDC}')\n",
        "              password_input.layout.display = 'none'\n",
        "              login_button.layout.display = 'none'\n",
        "\n",
        "      login_button.on_click(on_button_clicked)\n",
        "      display(widgets.VBox([password_input, login_button, output]))\n",
        "\n"
      ],
      "metadata": {
        "id": "4rPCVCTkbRjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка OpenAI API key"
      ],
      "metadata": {
        "id": "jJLX5JHD0NH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = MyTools()\n",
        "MyTools.set_key()"
      ],
      "metadata": {
        "id": "4Hu0481obkC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Базовый запрос к OpenAI"
      ],
      "metadata": {
        "id": "eWS8UNbF0aAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Выполнить базовый запрос\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "llm(\"Объясни large language models (LLM) одним предложением\")"
      ],
      "metadata": {
        "id": "REjvMeZ4YmA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# импортировать схему для сообщений чата и ChatGPT чтобы запрашивать модели chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "OT1peKTpb9g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"Ты специалист по Artificial Intelligence (AI)\"),\n",
        "    HumanMessage(content=\"Напишите код Python, который обучает нейронную сеть на смоделированных данных.\")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ],
      "metadata": {
        "id": "DZTaaBX1cK2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prompt шаблон"
      ],
      "metadata": {
        "id": "1Dht5DLO0s_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортировать prompt и определить PromptTemplate\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Вы опытный специалист по данным с опытом построения моделей глубокого обучения.\n",
        "Объясните концепцию {concept} в двух строках.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "1uNmK2R5dsqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "2kp4-ogqeXfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вызывать LLM с PromptTemplate\n",
        "\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ],
      "metadata": {
        "id": "-fRvpOoTd0Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt.format(concept=\"regularization\"))"
      ],
      "metadata": {
        "id": "v_jSuA9Ve3z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chains"
      ],
      "metadata": {
        "id": "qCqxIWllq7hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортировать LLMChain и определить  chain с LLM и prompt как параметр.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Выполнить chain только для указаной входной переменной.\n",
        "print(chain.run(\"autoencoder\"))"
      ],
      "metadata": {
        "id": "2hLiSCOZedEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определить второй prompt\n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Включите описание концепции {ml_concept} и объясните мне это, как будто мне 5 лет в 500 словах.\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "ziZoRTEMf3qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "print(explanation)"
      ],
      "metadata": {
        "id": "Rp6L6D_vgTIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Embeddings and VectorStores"
      ],
      "metadata": {
        "id": "EpcONB3ottf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])"
      ],
      "metadata": {
        "id": "6yeAN43qtw--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "V8ep3r7R2kp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0].page_content"
      ],
      "metadata": {
        "id": "_hWH5CEm2vbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ],
      "metadata": {
        "id": "YRYEO3DC3N8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "import tiktoken\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "FnPhPBKy3UTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}